# -*- coding: utf-8 -*-
"""Fetch_20_News_Group.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MGbh8tuBktAImNa7pKHbJqbNVSfPGWTL
"""

import numpy as np
import pandas as pd
from sklearn.datasets import fetch_20newsgroups

news=fetch_20newsgroups()

news.data

set(news.target)

headings= news.target_names
headings

news_train=fetch_20newsgroups(subset='train',categories=headings)
news_test=fetch_20newsgroups(subset='test',categories=headings)

news_train

news_train.data[1]

news_test.data[6]

print(len(news_train.data))

print(len(news_test.data))

total_data=fetch_20newsgroups(subset='all')
len(total_data.data)

from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer
from sklearn.pipeline import Pipeline
from sklearn.naive_bayes import MultinomialNB

model=Pipeline([('vector',TfidfVectorizer()),('Tfidf',TfidfTransformer()),('model',MultinomialNB())])

model.fit(news_train.data,news_train.target)

def predict_category(t,m=model,n=news_train):
  pred=m.predict([t])
  return n.target_names[pred[0]]

predict_category('Rolls Royce is a Luxury Brand')

predict_category('Mr. Narendra Modi is Our Prime Minister')

predict_category('Omkar Bohidar From Uganda')

#SPAM MAIL DATASET

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB

s=pd.read_csv(r"/content/spam.csv",encoding='ISO-8859-1')

s

s.info()

s.isnull().sum()

sn=s[['v1','v2']]

sn

sn.columns=['labels','messages']
sn

# @title labels

from matplotlib import pyplot as plt
import seaborn as sns
sn.groupby('labels').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)

sn['elabels']=sn['labels'].map({'ham':0, 'spam':1})

sn

ip=sn.messages
op=sn.elabels

xtr,xt,ytr,yt=train_test_split(ip,op,test_size=0.33)

print(xtr.shape,xt.shape,ytr.shape,yt.shape)

tfidf=TfidfVectorizer()
xtr=tfidf.fit_transform(xtr)
xt=tfidf.transform(xt)

algo=MultinomialNB()
algo.fit(xtr,ytr)

pred = algo.predict(xt)

from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score

acc=accuracy_score(pred,yt)
rec=recall_score(pred,yt)
pre=precision_score(pred,yt)
f1=f1_score(pred,yt)

print(acc,rec,pre,f1)

!pip install wordcloud

from wordcloud import WordCloud

def visualize(n):
  words=''
  for i in sn[sn.labels==n]['messages']:
    i.lower()
    words=words+i

  wc=WordCloud(width=600,height=400).generate(words)
  plt.imshow(wc)
  plt.axis('off')
  plt.show()

visualize('spam')

